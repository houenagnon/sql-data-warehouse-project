# ğŸ“¦ Modern Data Warehouse â€“ PostgreSQL Edition

## ğŸ§­ Overview

Ce projet met en Å“uvre un **Data Warehouse Moderne** sur PostgreSQL en utilisant une architecture multi-couches typique : **Bronze â†’ Silver â†’ Gold**.

Lâ€™objectif est de dÃ©montrer comment construire un pipeline ETL complet incluant :

* ingestion de donnÃ©es brutes
* transformations
* normalisation
* modÃ©lisation dimensionnelle
* gÃ©nÃ©ration de vues analytiques
* bonnes pratiques qualitÃ©

Ce projet reproduit le pipeline classique MS SQL Server â†’ mais adaptÃ© proprement au monde PostgreSQL.

---

## ğŸ› Architecture

```
+--------------------+
|   Source Files     |  CSV
+---------+----------+
          |
          v
+--------------------+
|     BRONZE Layer   |
|  (raw structured)  |
+---------+----------+
          |
          v
+--------------------+
|     SILVER Layer   |
|   (cleaned data)   |
+---------+----------+
          |
          v
+--------------------+
|      GOLD Layer    |
|  (dimensional BI)  |
+--------------------+
```

---

## ğŸ› ï¸ Tech Stack

|    Component | Tool                       |
| -----------: | :------------------------- |
|     Database | **PostgreSQL**             |
| Orchestrator | PL/pgSQL Stored Procedures |
|    Analytics | pgAdmin / SQL              |
|  Data Format | CSV                        |
|      Schemas | bronze, silver, gold       |

---

## ğŸ“‚ Repository Structure

```
/data
    /source_crm
    /source_erp
/sql
    bronze_tables.sql
    bronze_loader.sql
    silver_tables.sql
    silver_loader.sql
    gold_views.sql
README.md
```

---

## ğŸ“¥ Data Sources

Input located in:

```
data/source_crm/
data/source_erp/
```

Format:

* `.csv`
* headers included
* comma separated

---

## ğŸ—„ Database Setup

### 1. Create database

```sql
DROP DATABASE IF EXISTS "DataWarehouse";
CREATE DATABASE "DataWarehouse";
```

### 2. Create schemas

```sql
CREATE SCHEMA bronze;
CREATE SCHEMA silver;
CREATE SCHEMA gold;
```

---

## ğŸ§± Layer â€“ Bronze

### Tables

Located in:

```
sql/bronze_tables.sql
```

### Data loading procedure

Loads CSV â†’ Bronze

```sql
CALL bronze.load_bronze();
```

(function is implemented in PL/pgSQL)

---

## ğŸ§¼ Layer â€“ Silver

Silver cleans + standardizes:

* sexes
* dates
* strings
* categories
* costs
* data consistency
* removes duplicates

### Create tables

```
sql/silver_tables.sql
```

### Transformation procedure

```
CALL silver.load_silver();
```

---

## ğŸŸ¨ Layer â€“ Gold (Dimensional)

Designed following star-schema concepts:

### Views

```
gold.dim_customers
gold.dim_products
gold.fact_sales
```

Created by:

```sql
sql/gold_views.sql
```

---

## ğŸ” Data Quality Checks

Validated aspects:

* duplicates
* nullness
* unwanted spaces
* invalid dates
* referential join quality
* mapping consistency

Queries located in:

```
sql/silver_quality_checks.sql
```

---

## ğŸ“Š Example Queries

```sql
SELECT * FROM gold.fact_sales LIMIT 100;
SELECT country, COUNT(*) FROM gold.dim_customers GROUP BY 1;
SELECT product_line, SUM(sales_amount) FROM gold.fact_sales GROUP BY 1;
```

---

## ğŸ§ª Expected Outputs

* bronze â†’ equal to source files
* silver â†’ conform, standardized
* gold â†’ dimensional semantic layer ready for BI

---

## ğŸ Final Result

You get:

âœ” A functioning Data Warehouse
âœ” A clean ELT flow
âœ” Clean normalized customer / product data
âœ” Dimensional-ready analytics layer
âœ” High-quality SQL transformation logic

---

## ğŸš€ Improvements (future)

* dbt migration
* Airflow orchestration
* Dockerized PostgreSQL
* dashboard (Metabase / PowerBI)
* CDC / incremental load
* slowly changing dimensions
* quality scoring indicators

---

